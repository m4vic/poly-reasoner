# Polyreasoner Dependencies
# Install with: pip install -r requirements.txt

# Core dependency - LLM inference
# For GPU support on Windows:
# pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121

llama-cpp-python>=0.2.0
